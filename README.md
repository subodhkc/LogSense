# LogSense â€” Enterprise Log Analysis & RCA

LogSense is a professional, modular log analysis application built with Python and Streamlit. It helps TPMs, QA engineers, and support teams triage provisioning/installer logs (BIOS, SoftPaq, MSI, imaging, agents) and produce concise, defensible rootâ€‘cause analysis (RCA). AI assistance is available via local LLM or cloud.



## ğŸ” Key Features
- Secure log ingestion (ZIP and single-file) with robust parsing
- Structured preâ€‘AI RCA: error detection, correlations, and ruleâ€‘based recommendations
- Interactive timeline, test plan validation, and focused log filtering
- Advanced analytics: clustering, anomaly detection (SVM), decision trees
- PII redaction engine with configurable patterns
- Professional PDF reporting with corporate SaaS design and executive oneâ€‘pager
- Optional AI analysis: local (offline) model or OpenAI fallback

## ğŸ§° Setup

### 1. Clone and Setup
```bash
pip install -r requirements.txt
```

### 2. Run
```bash
streamlit run skc_log_analyzer.py
```

### 3. Folder Structure (condensed)
```
â”œâ”€â”€ skc_log_analyzer.py
â”œâ”€â”€ analysis.py
â”œâ”€â”€ redaction.py
â”œâ”€â”€ test_plan.py
â”œâ”€â”€ recommendations.py
â”œâ”€â”€ ai_rca.py                # Hybrid AI RCA (offline Phiâ€‘2 + OpenAI fallback)
â”œâ”€â”€ report/                  # PDF report package (generate_pdf, pdf_builder)
â”œâ”€â”€ setup.py
â”œâ”€â”€ clustering_model.py
â”œâ”€â”€ decision_tree_model.py
â”œâ”€â”€ anomaly_svm.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ plans/
â”‚   â”œâ”€â”€ dash_test_plan.json
â”‚   â””â”€â”€ softpaq_test_plan.json
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ redact.json
â”‚   â””â”€â”€ model.yaml   # Phiâ€‘2 config (model, generation params)
```



## ğŸ” Security
- Only redacted logs are sent to any external API (if enabled)
- All parsing, analytics, and local LLM inference run locally

## ğŸ“¦ Deployment
- Local: `streamlit run skc_log_analyzer.py`
- Docker (CPU): build with the provided `Dockerfile`

## ğŸ§  LLM Support (Phiâ€‘2 Migration)
- Default offline model: Microsoft Phiâ€‘2
- Optional LoRA adapters autoâ€‘load from `adapters/phi2-lora`
- OpenAI fallback supported if `OPENAI_API_KEY` is set

Env/config overrides (also see `config/model.yaml`):
- `MODEL_BACKEND`: `phi2` (default) or `legacy`
- `MODEL_NAME`: default `microsoft/phi-2` (CI uses a tiny model)
- `QUANTIZATION`: `none` | `8bit` | `4bit` (bitsandbytes; Linux recommended)
- `MAX_NEW_TOKENS`, `TEMPERATURE`, `TOP_P`, `REPETITION_PENALTY`

---




## UI Engine Toggles
- Use Python Engines (rules, validations, summaries)
- Use Local LLM (Phiâ€‘2)
- Use Cloud AI (OpenAI)

These appear in the sidebar and control what is executed and rendered.

## Credits
Built by Subodh Kc
Powered by Python, Streamlit, Transformers, and openâ€‘source intelligence
